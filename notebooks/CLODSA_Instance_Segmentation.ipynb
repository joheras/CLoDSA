{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Instance_Segmentation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxQekSqTht6I"
   },
   "source": [
    "# Augmenting a dataset for instance segmentation\n",
    "\n",
    "In this notebook, we illustrate how CLODSA can be employed to augment a dataset of images devoted to instance segmentation that was annotated using the [COCO format](http://cocodataset.org/#home). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YC_9o6-Jht6M"
   },
   "source": [
    "We will use a small dataset of shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3838
    },
    "colab_type": "code",
    "id": "QNhd1Ttiht6Q",
    "outputId": "0268f0b6-eecc-436a-ee85-05915b5f5dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-18 18:21:39--  https://www.dropbox.com/s/eus5u6ug1s7ftzc/shapes.zip?dl=0\n",
      "Resolviendo www.dropbox.com (www.dropbox.com)... 162.125.68.1, 2620:100:6024:1::a27d:4401\n",
      "Conectando con www.dropbox.com (www.dropbox.com)[162.125.68.1]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 301 Moved Permanently\n",
      "Ubicación: /s/raw/eus5u6ug1s7ftzc/shapes.zip [siguiente]\n",
      "--2019-01-18 18:21:39--  https://www.dropbox.com/s/raw/eus5u6ug1s7ftzc/shapes.zip\n",
      "Reutilizando la conexión con www.dropbox.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Ubicación: https://ucc5f89533b6d3c41b362c73b9f3.dl.dropboxusercontent.com/cd/0/inline/AZrdyznaDyEus3NypuLF2KENOG2Nm3xdk9WO_gGYyTuTHJ5nYUa54K1ClVQprnKcHIRTyuzC_M3V7Dm25UjqOcKzn4ZPZ6rZc4WhNchePhzbiCeHyXm3AeuTiDokzBz9IBb5MWCMMStrQukbbcMe6RsPYdpI1Y1BQNRKhF9jyqc0Hdo_JHNdD-XdMtr9SiEdXks/file# [siguiente]\n",
      "--2019-01-18 18:21:40--  https://ucc5f89533b6d3c41b362c73b9f3.dl.dropboxusercontent.com/cd/0/inline/AZrdyznaDyEus3NypuLF2KENOG2Nm3xdk9WO_gGYyTuTHJ5nYUa54K1ClVQprnKcHIRTyuzC_M3V7Dm25UjqOcKzn4ZPZ6rZc4WhNchePhzbiCeHyXm3AeuTiDokzBz9IBb5MWCMMStrQukbbcMe6RsPYdpI1Y1BQNRKhF9jyqc0Hdo_JHNdD-XdMtr9SiEdXks/file\n",
      "Resolviendo ucc5f89533b6d3c41b362c73b9f3.dl.dropboxusercontent.com (ucc5f89533b6d3c41b362c73b9f3.dl.dropboxusercontent.com)... 162.125.68.6, 2620:100:6024:6::a27d:4406\n",
      "Conectando con ucc5f89533b6d3c41b362c73b9f3.dl.dropboxusercontent.com (ucc5f89533b6d3c41b362c73b9f3.dl.dropboxusercontent.com)[162.125.68.6]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 FOUND\n",
      "Ubicación: /cd/0/inline2/AZphJ_gpA8An4RCze9fdU5xzCR3EklSDuN6ArzQCIR7IkQXrwwHjGTinlKi6wlpgyO7_jpiPuI3GK-FmExr-UBlJwePSAyTCEn6M2U9WHMtHAwjUcAh0hHUbOWNxIZ29TPZe3trVC_Ex2cKDCkWfVAolkwIUH9hVupQBWiu8UY3tY907cWVFsMCgLTZn0kuJ8fhP0iYRoWDzBG_m4_hlPgh5_6VeSNGZAMTEKTB3ItfJAYI2aPqr_en9lttMy1YJhwp2UepMBpk0EDu_4aRNafjV1zr-wCs3fPgnFaiENLsTSFsKceJEldZr7_93deBw_8690OQytl__HLU5JTim32xj1T0zTRo8iIRYtTa2Gn9-uW-MiZsXI6UAttJ35LydJO_bbhdmjjpQNiYYVO2LZ1vUlUtHRPevveFmF7mbOJ_iL5zWcBFlkpttGaqL7YfHqqc/file [siguiente]\n",
      "--2019-01-18 18:21:40--  https://ucc5f89533b6d3c41b362c73b9f3.dl.dropboxusercontent.com/cd/0/inline2/AZphJ_gpA8An4RCze9fdU5xzCR3EklSDuN6ArzQCIR7IkQXrwwHjGTinlKi6wlpgyO7_jpiPuI3GK-FmExr-UBlJwePSAyTCEn6M2U9WHMtHAwjUcAh0hHUbOWNxIZ29TPZe3trVC_Ex2cKDCkWfVAolkwIUH9hVupQBWiu8UY3tY907cWVFsMCgLTZn0kuJ8fhP0iYRoWDzBG_m4_hlPgh5_6VeSNGZAMTEKTB3ItfJAYI2aPqr_en9lttMy1YJhwp2UepMBpk0EDu_4aRNafjV1zr-wCs3fPgnFaiENLsTSFsKceJEldZr7_93deBw_8690OQytl__HLU5JTim32xj1T0zTRo8iIRYtTa2Gn9-uW-MiZsXI6UAttJ35LydJO_bbhdmjjpQNiYYVO2LZ1vUlUtHRPevveFmF7mbOJ_iL5zWcBFlkpttGaqL7YfHqqc/file\n",
      "Reutilizando la conexión con ucc5f89533b6d3c41b362c73b9f3.dl.dropboxusercontent.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 5202 (5,1K) [application/zip]\n",
      "Guardando como: “shapes.zip”\n",
      "\n",
      "shapes.zip          100%[===================>]   5,08K  --.-KB/s    en 0s      \n",
      "\n",
      "2019-01-18 18:21:41 (394 MB/s) - “shapes.zip” guardado [5202/5202]\n",
      "\n",
      "Archive:  shapes.zip\n",
      "   creating: shapes/\n",
      "  inflating: shapes/1000.jpeg        \n",
      "  inflating: shapes/1001.jpeg        \n",
      "  inflating: shapes/annotations.json  \n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/eus5u6ug1s7ftzc/shapes.zip?dl=0 -O shapes.zip\n",
    "!unzip shapes.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kAy0Hvnbht6i"
   },
   "source": [
    "We can check the elements of the shapes folder that are a json file with the coco annotation and two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "XEJ0pRfRht6k",
    "outputId": "9cc7906d-f241-403d-b41e-7b8b4ff9112c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.jpeg  1001.jpeg  annotations.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls shapes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaBilQHUht6u"
   },
   "source": [
    "## Augmentation techniques\n",
    "\n",
    "For this example, we consider three augmentation techniques. \n",
    "\n",
    "The augmentation techniques applied in this example are:\n",
    "- Rotation.\n",
    "- Flip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wCILufF2ht6y"
   },
   "source": [
    "## Installing the necessary libraries\n",
    "\n",
    "In case that CLODSA is not installed in your system, the first task consists in installing it using ``pip``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "FWTm8dG3ht6y",
    "outputId": "ae3a8866-cbfb-4863-a357-248e1e56989c"
   },
   "outputs": [],
   "source": [
    "!pip install clodsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1q3x_OFht66"
   },
   "source": [
    "## Loading the necessary libraries\n",
    "\n",
    "The first step in the pipeline consists in loading the necessary libraries to apply the data augmentation techniques in CLODSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JqWBswFyht68",
    "outputId": "77349188-126d-4e4d-93fa-929ec33ad573"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from clodsa.augmentors.augmentorFactory import createAugmentor\n",
    "from clodsa.transformers.transformerFactory import transformerGenerator\n",
    "from clodsa.techniques.techniqueFactory import createTechnique\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CBP59dqqht7E"
   },
   "source": [
    "## Creating the augmentor object\n",
    "\n",
    "As explained in the documentation of CLODSA, we need to specify some parameters for the augmentation process, and use them to create an augmentor object.  \n",
    "\n",
    "_The kind of problem_. In this case, we are working in an instance segmentation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQ5q8WVnht7G"
   },
   "outputs": [],
   "source": [
    "PROBLEM = \"instance_segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D46gdf-4ht7K"
   },
   "source": [
    "_The annotation mode_. The annotation is provided using the coco format in a file called annotations.json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrlRg-FVht7M"
   },
   "outputs": [],
   "source": [
    "ANNOTATION_MODE = \"coco\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cn-uF33Oht7S"
   },
   "source": [
    "_The input path_. The input path containing the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78jPXCj2ht7U"
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = \"shapes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9kGGhs4ht7a"
   },
   "source": [
    "_The generation mode_. In this case, linear, that is, all the augmentation techniques are applied to all the images of the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCweCzLeht7c"
   },
   "outputs": [],
   "source": [
    "GENERATION_MODE = \"linear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6WljljVht7g"
   },
   "source": [
    "_The output mode_. The generated images will be stored in a new folder called output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4uKKcJUht7i"
   },
   "outputs": [],
   "source": [
    "OUTPUT_MODE = \"coco\"\n",
    "OUTPUT_PATH= \"output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9R79LEvVht7o"
   },
   "source": [
    "Using the above information, we can create our augmentor object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQ9wyiQuht7q"
   },
   "outputs": [],
   "source": [
    "augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXOfuq90ht7w"
   },
   "source": [
    "## Adding the augmentation techniques\n",
    "\n",
    "Now, we define the techniques that will be applied in our augmentation process and add them to our augmentor object. To illustrate the transformations, we will use the following image of the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we must define a transformer generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformerGenerator(PROBLEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4PfSKW-ht74"
   },
   "source": [
    "_Rotations:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajKE-mkDht74"
   },
   "outputs": [],
   "source": [
    "for angle in [90,180]:\n",
    "    rotate = createTechnique(\"rotate\", {\"angle\" : angle})\n",
    "    augmentor.addTransformer(transformer(rotate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Flips:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = createTechnique(\"flip\",{\"flip\":1})\n",
    "augmentor.addTransformer(transformer(flip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwE-qSYLht9I"
   },
   "source": [
    "## Applying the augmentation process\n",
    "\n",
    "Finally, we apply the augmentation process (this might take some time depending on the number of images of the original dataset and the number of transformations that will be applied). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbW5YVE9ht9I"
   },
   "outputs": [],
   "source": [
    "augmentor.applyAugmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the elements of the output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_1000.jpeg  1_1000.jpeg  2_1000.jpeg  annotation.json\r\n",
      "0_1001.jpeg  1_1001.jpeg  2_1001.jpeg\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can visualize the results using some of the tools provided by [the COCO API](https://github.com/cocodataset/cocoapi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /home/jonathan/.virtualenvs/cv/lib/python3.6/site-packages (2.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = 'output/'\n",
    "annotation_file = 'output/annotation.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "example_coco = COCO(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom COCO categories: \n",
      "square circle triangle\n",
      "\n",
      "Custom COCO supercategories: \n",
      "shape\n"
     ]
    }
   ],
   "source": [
    "categories = example_coco.loadCats(example_coco.getCatIds())\n",
    "category_names = [category['name'] for category in categories]\n",
    "print('Custom COCO categories: \\n{}\\n'.format(' '.join(category_names)))\n",
    "\n",
    "category_names = set([category['supercategory'] for category in categories])\n",
    "print('Custom COCO supercategories: \\n{}'.format(' '.join(category_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each execution of the following cells show a different image of the output dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = example_coco.getCatIds(catNms=['square'])\n",
    "image_ids = example_coco.getImgIds(catIds=category_ids)\n",
    "image_data = example_coco.loadImgs(image_ids[np.random.randint(0, len(image_ids))])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2,\n",
       " 'file_name': '1_1000.jpeg',\n",
       " 'width': 128,\n",
       " 'height': 128,\n",
       " 'date_captured': '',\n",
       " 'license': 1,\n",
       " 'coco_url': '',\n",
       " 'flickr_url': ''}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = io.imread(image_directory + image_data['file_name'])\n",
    "plt.imshow(image); plt.axis('off')\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "annotation_ids = example_coco.getAnnIds(imgIds=image_data['id'], catIds=category_ids, iscrowd=None)\n",
    "annotations = example_coco.loadAnns(annotation_ids)\n",
    "example_coco.showAnns(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are executing this notebook in Colaboratory, you need to download the generated files. To that aim, you can create a zip folder and download it using the following commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r shapes.zip output\n",
    "from google.colab import files\n",
    "files.download('shapes.zip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CLODSA_Nuclei.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
